{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Adding text features\n",
                "\n",
                "So far, the tutorials have dealt with _tabular_ data only. This tutorial will show you to make predictors out of text features, such as clinical notes, within `timeseriesflattener`.\n",
                "\n",
                "Specifically, this tutorial will cover _how to generate flattened predictors from already embedded text._\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## The dataset\n",
                "\n",
                "To start out, let's load a synthetic dataset containing text. As with all other features, each row in the dataset needs an ID, a timestamp, and the feature value.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "from __future__ import annotations\n",
                "\n",
                "from timeseriesflattener.testing.load_synth_data import load_synth_text"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div><style>\n",
                            ".dataframe > thead > tr,\n",
                            ".dataframe > tbody > tr {\n",
                            "  text-align: right;\n",
                            "  white-space: pre-wrap;\n",
                            "}\n",
                            "</style>\n",
                            "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>entity_id</th><th>timestamp</th><th>value</th></tr><tr><td>i64</td><td>datetime[μs]</td><td>str</td></tr></thead><tbody><tr><td>4647</td><td>1967-07-19 00:22:00</td><td>&quot;The patient went into a medica…</td></tr><tr><td>2007</td><td>1966-11-25 02:02:00</td><td>&quot;The patient is taken to the em…</td></tr><tr><td>5799</td><td>1967-09-19 12:31:00</td><td>&quot;The patient, described as a 7-…</td></tr><tr><td>1319</td><td>1969-07-21 23:16:00</td><td>&quot;The patient had been left on a…</td></tr><tr><td>4234</td><td>1966-04-14 22:04:00</td><td>&quot;The patient had had some sever…</td></tr></tbody></table></div>"
                        ],
                        "text/plain": [
                            "shape: (5, 3)\n",
                            "┌───────────┬─────────────────────┬─────────────────────────────────┐\n",
                            "│ entity_id ┆ timestamp           ┆ value                           │\n",
                            "│ ---       ┆ ---                 ┆ ---                             │\n",
                            "│ i64       ┆ datetime[μs]        ┆ str                             │\n",
                            "╞═══════════╪═════════════════════╪═════════════════════════════════╡\n",
                            "│ 4647      ┆ 1967-07-19 00:22:00 ┆ The patient went into a medica… │\n",
                            "│ 2007      ┆ 1966-11-25 02:02:00 ┆ The patient is taken to the em… │\n",
                            "│ 5799      ┆ 1967-09-19 12:31:00 ┆ The patient, described as a 7-… │\n",
                            "│ 1319      ┆ 1969-07-21 23:16:00 ┆ The patient had been left on a… │\n",
                            "│ 4234      ┆ 1966-04-14 22:04:00 ┆ The patient had had some sever… │\n",
                            "└───────────┴─────────────────────┴─────────────────────────────────┘"
                        ]
                    },
                    "execution_count": 11,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "synth_text = load_synth_text()\n",
                "synth_text.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Generating predictors from embedded text\n",
                "\n",
                "As generating text embeddings can often take a while, it can be an advantageous to embed the text before using `timeseriesflattener` to speed up the computation if you're generating multiple datasets. This first block will show you how to format a dataframe with embedded text for `timeseriesflattener`.\n",
                "\n",
                "To start, let's embed the synthetic text data using TF-IDF. You can use any form of text-embedding you want - the only constraint is that the result of the embedding function should be a dataframe with an `entity_id_col`, `timestamp_col` and any number of columns containing the embeddings, with a single value in each column.\n",
                "\n",
                "For purposes of demonstration, we will fit a small TF-IDF model to the data and use it to embed the text.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%capture\n",
                "import polars as pl\n",
                "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                "\n",
                "\n",
                "# define function to embed text and return a dataframe\n",
                "def embed_text_to_df(text: list[str]) -> pl.DataFrame:\n",
                "    tfidf_model = TfidfVectorizer(max_features=10)\n",
                "    embeddings = tfidf_model.fit_transform(text)\n",
                "    return pl.DataFrame(embeddings.toarray(), schema=tfidf_model.get_feature_names_out().tolist())\n",
                "\n",
                "\n",
                "# embed text\n",
                "embedded_text = embed_text_to_df(text=synth_text[\"value\"].to_list())\n",
                "# drop the text column from the original dataframe\n",
                "metadata_only = synth_text.drop([\"value\"])\n",
                "# concatenate the metadata and the embedded text\n",
                "embedded_text_with_metadata = pl.concat([metadata_only, embedded_text], how=\"horizontal\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div><style>\n",
                            ".dataframe > thead > tr,\n",
                            ".dataframe > tbody > tr {\n",
                            "  text-align: right;\n",
                            "  white-space: pre-wrap;\n",
                            "}\n",
                            "</style>\n",
                            "<small>shape: (5, 12)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>entity_id</th><th>timestamp</th><th>and</th><th>for</th><th>in</th><th>of</th><th>or</th><th>patient</th><th>that</th><th>the</th><th>to</th><th>was</th></tr><tr><td>i64</td><td>datetime[μs]</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>4647</td><td>1967-07-19 00:22:00</td><td>0.175872</td><td>0.182066</td><td>0.249848</td><td>0.15843</td><td>0.0</td><td>0.023042</td><td>0.311389</td><td>0.529966</td><td>0.490203</td><td>0.479312</td></tr><tr><td>2007</td><td>1966-11-25 02:02:00</td><td>0.24487</td><td>0.0</td><td>0.135282</td><td>0.064337</td><td>0.465084</td><td>0.336859</td><td>0.151743</td><td>0.729861</td><td>0.179161</td><td>0.0</td></tr><tr><td>5799</td><td>1967-09-19 12:31:00</td><td>0.192367</td><td>0.232332</td><td>0.283402</td><td>0.336952</td><td>0.0</td><td>0.176422</td><td>0.238416</td><td>0.646879</td><td>0.250217</td><td>0.382277</td></tr><tr><td>1319</td><td>1969-07-21 23:16:00</td><td>0.165635</td><td>0.200046</td><td>0.183015</td><td>0.261115</td><td>0.125837</td><td>0.151906</td><td>0.205285</td><td>0.759528</td><td>0.403961</td><td>0.098747</td></tr><tr><td>4234</td><td>1966-04-14 22:04:00</td><td>0.493461</td><td>0.119196</td><td>0.272619</td><td>0.207444</td><td>0.0</td><td>0.045256</td><td>0.183475</td><td>0.588324</td><td>0.433253</td><td>0.235349</td></tr></tbody></table></div>"
                        ],
                        "text/plain": [
                            "shape: (5, 12)\n",
                            "┌───────────┬────────────────┬──────────┬──────────┬───┬──────────┬──────────┬──────────┬──────────┐\n",
                            "│ entity_id ┆ timestamp      ┆ and      ┆ for      ┆ … ┆ that     ┆ the      ┆ to       ┆ was      │\n",
                            "│ ---       ┆ ---            ┆ ---      ┆ ---      ┆   ┆ ---      ┆ ---      ┆ ---      ┆ ---      │\n",
                            "│ i64       ┆ datetime[μs]   ┆ f64      ┆ f64      ┆   ┆ f64      ┆ f64      ┆ f64      ┆ f64      │\n",
                            "╞═══════════╪════════════════╪══════════╪══════════╪═══╪══════════╪══════════╪══════════╪══════════╡\n",
                            "│ 4647      ┆ 1967-07-19     ┆ 0.175872 ┆ 0.182066 ┆ … ┆ 0.311389 ┆ 0.529966 ┆ 0.490203 ┆ 0.479312 │\n",
                            "│           ┆ 00:22:00       ┆          ┆          ┆   ┆          ┆          ┆          ┆          │\n",
                            "│ 2007      ┆ 1966-11-25     ┆ 0.24487  ┆ 0.0      ┆ … ┆ 0.151743 ┆ 0.729861 ┆ 0.179161 ┆ 0.0      │\n",
                            "│           ┆ 02:02:00       ┆          ┆          ┆   ┆          ┆          ┆          ┆          │\n",
                            "│ 5799      ┆ 1967-09-19     ┆ 0.192367 ┆ 0.232332 ┆ … ┆ 0.238416 ┆ 0.646879 ┆ 0.250217 ┆ 0.382277 │\n",
                            "│           ┆ 12:31:00       ┆          ┆          ┆   ┆          ┆          ┆          ┆          │\n",
                            "│ 1319      ┆ 1969-07-21     ┆ 0.165635 ┆ 0.200046 ┆ … ┆ 0.205285 ┆ 0.759528 ┆ 0.403961 ┆ 0.098747 │\n",
                            "│           ┆ 23:16:00       ┆          ┆          ┆   ┆          ┆          ┆          ┆          │\n",
                            "│ 4234      ┆ 1966-04-14     ┆ 0.493461 ┆ 0.119196 ┆ … ┆ 0.183475 ┆ 0.588324 ┆ 0.433253 ┆ 0.235349 │\n",
                            "│           ┆ 22:04:00       ┆          ┆          ┆   ┆          ┆          ┆          ┆          │\n",
                            "└───────────┴────────────────┴──────────┴──────────┴───┴──────────┴──────────┴──────────┴──────────┘"
                        ]
                    },
                    "execution_count": 13,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "embedded_text_with_metadata.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now that we have our embeddings in a dataframe including the `entity_id` and `timestamp`, we can simply pass it to `PredictorSpec`!\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": [
                "import datetime as dt\n",
                "\n",
                "import numpy as np\n",
                "from timeseriesflattener import PredictorSpec, ValueFrame\n",
                "from timeseriesflattener.aggregators import MeanAggregator\n",
                "\n",
                "text_spec = PredictorSpec.from_primitives(\n",
                "    df=embedded_text_with_metadata,\n",
                "    entity_id_col_name=\"entity_id\",\n",
                "    value_timestamp_col_name=\"timestamp\",\n",
                "    lookbehind_days=[365, 730],\n",
                "    aggregators=[\"mean\"],\n",
                "    column_prefix=\"pred_tfidf\",\n",
                "    fallback=np.nan,\n",
                ")\n",
                "\n",
                "# Alternatively, if you prefer types\n",
                "text_spec = PredictorSpec(\n",
                "    ValueFrame(\n",
                "        init_df=embedded_text_with_metadata,\n",
                "        entity_id_col_name=\"entity_id\",\n",
                "        value_timestamp_col_name=\"timestamp\",\n",
                "    ),\n",
                "    lookbehind_distances=[dt.timedelta(days=365), dt.timedelta(days=730)],\n",
                "    aggregators=[MeanAggregator()],\n",
                "    fallback=np.nan,\n",
                "    column_prefix=\"pred_tfidf\",\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's make some features!\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We are creating 10\\*2=20 features: 1 for each embedding for each lookbehind (365 and 730 days), using the mean aggregation function.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "00b7f5319c1d42db807cc7976df1e127",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Output()"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Processing spec: ['and', 'for', 'in', 'of', 'or', 'patient', 'that', 'the', 'to', 'was']\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "Processing spec: ['and', 'for', 'in', 'of', 'or', 'patient', 'that', 'the', 'to', 'was']\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
                        ],
                        "text/plain": []
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# make features how you would normally\n",
                "from timeseriesflattener import Flattener, PredictionTimeFrame\n",
                "from timeseriesflattener.testing.load_synth_data import load_synth_prediction_times\n",
                "\n",
                "flattener = Flattener(\n",
                "    predictiontime_frame=PredictionTimeFrame(\n",
                "        init_df=load_synth_prediction_times(),\n",
                "        entity_id_col_name=\"entity_id\",\n",
                "        timestamp_col_name=\"timestamp\",\n",
                "    )\n",
                ")\n",
                "\n",
                "df = flattener.aggregate_timeseries(specs=[text_spec]).df"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's check the output.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div><style>\n",
                            ".dataframe > thead > tr,\n",
                            ".dataframe > tbody > tr {\n",
                            "  text-align: right;\n",
                            "  white-space: pre-wrap;\n",
                            "}\n",
                            "</style>\n",
                            "<small>shape: (5, 23)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>entity_id</th><th>timestamp</th><th>prediction_time_uuid</th><th>pred_tfidf_and_within_0_to_365_days_mean_fallback_nan</th><th>pred_tfidf_for_within_0_to_365_days_mean_fallback_nan</th><th>pred_tfidf_in_within_0_to_365_days_mean_fallback_nan</th><th>pred_tfidf_of_within_0_to_365_days_mean_fallback_nan</th><th>pred_tfidf_or_within_0_to_365_days_mean_fallback_nan</th><th>pred_tfidf_patient_within_0_to_365_days_mean_fallback_nan</th><th>pred_tfidf_that_within_0_to_365_days_mean_fallback_nan</th><th>pred_tfidf_the_within_0_to_365_days_mean_fallback_nan</th><th>pred_tfidf_to_within_0_to_365_days_mean_fallback_nan</th><th>pred_tfidf_was_within_0_to_365_days_mean_fallback_nan</th><th>pred_tfidf_and_within_0_to_730_days_mean_fallback_nan</th><th>pred_tfidf_for_within_0_to_730_days_mean_fallback_nan</th><th>pred_tfidf_in_within_0_to_730_days_mean_fallback_nan</th><th>pred_tfidf_of_within_0_to_730_days_mean_fallback_nan</th><th>pred_tfidf_or_within_0_to_730_days_mean_fallback_nan</th><th>pred_tfidf_patient_within_0_to_730_days_mean_fallback_nan</th><th>pred_tfidf_that_within_0_to_730_days_mean_fallback_nan</th><th>pred_tfidf_the_within_0_to_730_days_mean_fallback_nan</th><th>pred_tfidf_to_within_0_to_730_days_mean_fallback_nan</th><th>pred_tfidf_was_within_0_to_730_days_mean_fallback_nan</th></tr><tr><td>i64</td><td>datetime[μs]</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>6840</td><td>1965-11-02 07:17:00</td><td>&quot;6840-1965-11-02 07:17:00.00000…</td><td>0.155821</td><td>0.376386</td><td>0.258256</td><td>0.573168</td><td>0.355142</td><td>0.071452</td><td>0.096561</td><td>0.28581</td><td>0.45603</td><td>0.092896</td><td>0.155821</td><td>0.376386</td><td>0.258256</td><td>0.573168</td><td>0.355142</td><td>0.071452</td><td>0.096561</td><td>0.28581</td><td>0.45603</td><td>0.092896</td></tr><tr><td>2039</td><td>1966-04-20 05:06:00</td><td>&quot;2039-1966-04-20 05:06:00.00000…</td><td>0.108015</td><td>0.0</td><td>0.596744</td><td>0.11352</td><td>0.0</td><td>0.099062</td><td>0.133872</td><td>0.693431</td><td>0.210747</td><td>0.257581</td><td>0.108015</td><td>0.0</td><td>0.596744</td><td>0.11352</td><td>0.0</td><td>0.099062</td><td>0.133872</td><td>0.693431</td><td>0.210747</td><td>0.257581</td></tr><tr><td>9496</td><td>1966-12-06 06:44:00</td><td>&quot;9496-1966-12-06 06:44:00.00000…</td><td>0.279955</td><td>0.0</td><td>0.30933</td><td>0.294222</td><td>0.0</td><td>0.256749</td><td>0.0</td><td>0.513498</td><td>0.546216</td><td>0.3338</td><td>0.279955</td><td>0.0</td><td>0.30933</td><td>0.294222</td><td>0.0</td><td>0.256749</td><td>0.0</td><td>0.513498</td><td>0.546216</td><td>0.3338</td></tr><tr><td>7281</td><td>1967-06-05 00:41:00</td><td>&quot;7281-1967-06-05 00:41:00.00000…</td><td>0.289663</td><td>0.04373</td><td>0.280049</td><td>0.304425</td><td>0.385111</td><td>0.332065</td><td>0.269251</td><td>0.464891</td><td>0.211934</td><td>0.388547</td><td>0.289663</td><td>0.04373</td><td>0.280049</td><td>0.304425</td><td>0.385111</td><td>0.332065</td><td>0.269251</td><td>0.464891</td><td>0.211934</td><td>0.388547</td></tr><tr><td>7424</td><td>1967-07-13 15:01:00</td><td>&quot;7424-1967-07-13 15:01:00.00000…</td><td>0.153907</td><td>0.092941</td><td>0.170056</td><td>0.107834</td><td>0.389756</td><td>0.282299</td><td>0.063583</td><td>0.682222</td><td>0.475452</td><td>0.0</td><td>0.153907</td><td>0.092941</td><td>0.170056</td><td>0.107834</td><td>0.389756</td><td>0.282299</td><td>0.063583</td><td>0.682222</td><td>0.475452</td><td>0.0</td></tr></tbody></table></div>"
                        ],
                        "text/plain": [
                            "shape: (5, 23)\n",
                            "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
                            "│ entity_id ┆ timestamp ┆ predictio ┆ pred_tfid ┆ … ┆ pred_tfid ┆ pred_tfid ┆ pred_tfid ┆ pred_tfi │\n",
                            "│ ---       ┆ ---       ┆ n_time_uu ┆ f_and_wit ┆   ┆ f_that_wi ┆ f_the_wit ┆ f_to_with ┆ df_was_w │\n",
                            "│ i64       ┆ datetime[ ┆ id        ┆ hin_0_to_ ┆   ┆ thin_0_to ┆ hin_0_to_ ┆ in_0_to_7 ┆ ithin_0_ │\n",
                            "│           ┆ μs]       ┆ ---       ┆ 365…      ┆   ┆ _73…      ┆ 730…      ┆ 30_…      ┆ to_730…  │\n",
                            "│           ┆           ┆ str       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
                            "│           ┆           ┆           ┆ f64       ┆   ┆ f64       ┆ f64       ┆ f64       ┆ f64      │\n",
                            "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
                            "│ 6840      ┆ 1965-11-0 ┆ 6840-1965 ┆ 0.155821  ┆ … ┆ 0.096561  ┆ 0.28581   ┆ 0.45603   ┆ 0.092896 │\n",
                            "│           ┆ 2         ┆ -11-02    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
                            "│           ┆ 07:17:00  ┆ 07:17:00. ┆           ┆   ┆           ┆           ┆           ┆          │\n",
                            "│           ┆           ┆ 00000…    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
                            "│ 2039      ┆ 1966-04-2 ┆ 2039-1966 ┆ 0.108015  ┆ … ┆ 0.133872  ┆ 0.693431  ┆ 0.210747  ┆ 0.257581 │\n",
                            "│           ┆ 0         ┆ -04-20    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
                            "│           ┆ 05:06:00  ┆ 05:06:00. ┆           ┆   ┆           ┆           ┆           ┆          │\n",
                            "│           ┆           ┆ 00000…    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
                            "│ 9496      ┆ 1966-12-0 ┆ 9496-1966 ┆ 0.279955  ┆ … ┆ 0.0       ┆ 0.513498  ┆ 0.546216  ┆ 0.3338   │\n",
                            "│           ┆ 6         ┆ -12-06    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
                            "│           ┆ 06:44:00  ┆ 06:44:00. ┆           ┆   ┆           ┆           ┆           ┆          │\n",
                            "│           ┆           ┆ 00000…    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
                            "│ 7281      ┆ 1967-06-0 ┆ 7281-1967 ┆ 0.289663  ┆ … ┆ 0.269251  ┆ 0.464891  ┆ 0.211934  ┆ 0.388547 │\n",
                            "│           ┆ 5         ┆ -06-05    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
                            "│           ┆ 00:41:00  ┆ 00:41:00. ┆           ┆   ┆           ┆           ┆           ┆          │\n",
                            "│           ┆           ┆ 00000…    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
                            "│ 7424      ┆ 1967-07-1 ┆ 7424-1967 ┆ 0.153907  ┆ … ┆ 0.063583  ┆ 0.682222  ┆ 0.475452  ┆ 0.0      │\n",
                            "│           ┆ 3         ┆ -07-13    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
                            "│           ┆ 15:01:00  ┆ 15:01:00. ┆           ┆   ┆           ┆           ┆           ┆          │\n",
                            "│           ┆           ┆ 00000…    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
                            "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
                        ]
                    },
                    "execution_count": 16,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import polars as pl\n",
                "import polars.selectors as cs\n",
                "\n",
                "# dropping na values in float columns (no embeddings within the lookbehind periods) for the sake of this example\n",
                "df.filter(pl.all_horizontal(cs.float().is_not_nan())).head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "And just like that, you're ready to make a prediction model!\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.10.9 ('.venv': poetry)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.18"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "9e85d6a49b1f06126f30ca9ae16ded22dd7c17d2dbfabea9098dc6424f12e12a"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}

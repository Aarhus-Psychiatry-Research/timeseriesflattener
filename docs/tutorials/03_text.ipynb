{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Adding text features\n",
                "\n",
                "So far, the tutorials have dealt with _tabular_ data only. This tutorial will show you to make predictors out of text features, such as clinical notes, within `timeseriesflattener`.\n",
                "\n",
                "Specifically, this tutorial will cover *how to generate flattened predictors from already embedded text.*"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## The dataset\n",
                "\n",
                "To start out, let's load a synthetic dataset containing text. As with all other features, each row in the dataset needs an ID, a timestamp, and the feature value. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "from __future__ import annotations\n",
                "\n",
                "from timeseriesflattener.testing.load_synth_data import load_synth_text"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div><style>\n",
                            ".dataframe > thead > tr,\n",
                            ".dataframe > tbody > tr {\n",
                            "  text-align: right;\n",
                            "  white-space: pre-wrap;\n",
                            "}\n",
                            "</style>\n",
                            "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>entity_id</th><th>timestamp</th><th>value</th></tr><tr><td>i64</td><td>datetime[μs]</td><td>str</td></tr></thead><tbody><tr><td>4647</td><td>1967-07-19 00:22:00</td><td>&quot;The patient we…</td></tr><tr><td>2007</td><td>1966-11-25 02:02:00</td><td>&quot;The patient is…</td></tr><tr><td>5799</td><td>1967-09-19 12:31:00</td><td>&quot;The patient, d…</td></tr><tr><td>1319</td><td>1969-07-21 23:16:00</td><td>&quot;The patient ha…</td></tr><tr><td>4234</td><td>1966-04-14 22:04:00</td><td>&quot;The patient ha…</td></tr></tbody></table></div>"
                        ],
                        "text/plain": [
                            "shape: (5, 3)\n",
                            "┌───────────┬─────────────────────┬───────────────────────────────────┐\n",
                            "│ entity_id ┆ timestamp           ┆ value                             │\n",
                            "│ ---       ┆ ---                 ┆ ---                               │\n",
                            "│ i64       ┆ datetime[μs]        ┆ str                               │\n",
                            "╞═══════════╪═════════════════════╪═══════════════════════════════════╡\n",
                            "│ 4647      ┆ 1967-07-19 00:22:00 ┆ The patient went into a medicall… │\n",
                            "│ 2007      ┆ 1966-11-25 02:02:00 ┆ The patient is taken to the emer… │\n",
                            "│ 5799      ┆ 1967-09-19 12:31:00 ┆ The patient, described as a 7-mo… │\n",
                            "│ 1319      ┆ 1969-07-21 23:16:00 ┆ The patient had been left on a b… │\n",
                            "│ 4234      ┆ 1966-04-14 22:04:00 ┆ The patient had had some severe … │\n",
                            "└───────────┴─────────────────────┴───────────────────────────────────┘"
                        ]
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "synth_text = load_synth_text()\n",
                "synth_text.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Generating predictors from embedded text\n",
                "\n",
                "As generating text embeddings can often take a while, it can be an advantageous to embed the text before using `timeseriesflattener` to speed up the computation if you're generating multiple datasets. This first block will show you how to format a dataframe with embedded text for `timeseriesflattener`.\n",
                "\n",
                "To start, let's embed the synthetic text data using TF-IDF. You can use any form of text-embedding you want - the only constraint is that the result of the embedding function should be a dataframe with an `entity_id_col`, `timestamp_col` and any number of columns containing the embeddings, with a single value in each column. \n",
                "\n",
                "For purposes of demonstration, we will fit a small TF-IDF model to the data and use it to embed the text."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%capture\n",
                "import polars as pl\n",
                "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                "\n",
                "\n",
                "# define function to embed text and return a dataframe\n",
                "def embed_text_to_df(text: list[str]) -> pl.DataFrame:\n",
                "    tfidf_model = TfidfVectorizer(max_features=10)\n",
                "    embeddings = tfidf_model.fit_transform(text)\n",
                "    return pl.DataFrame(embeddings.toarray(), schema=tfidf_model.get_feature_names_out().tolist())\n",
                "\n",
                "\n",
                "# embed text\n",
                "embedded_text = embed_text_to_df(text=synth_text[\"value\"].to_list())\n",
                "# drop the text column from the original dataframe\n",
                "metadata_only = synth_text.drop(columns=[\"value\"])\n",
                "# concatenate the metadata and the embedded text\n",
                "embedded_text_with_metadata = pl.concat([metadata_only, embedded_text], how=\"horizontal\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div><style>\n",
                            ".dataframe > thead > tr,\n",
                            ".dataframe > tbody > tr {\n",
                            "  text-align: right;\n",
                            "  white-space: pre-wrap;\n",
                            "}\n",
                            "</style>\n",
                            "<small>shape: (5, 12)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>entity_id</th><th>timestamp</th><th>and</th><th>for</th><th>in</th><th>of</th><th>or</th><th>patient</th><th>that</th><th>the</th><th>to</th><th>was</th></tr><tr><td>i64</td><td>datetime[μs]</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>4647</td><td>1967-07-19 00:22:00</td><td>0.175872</td><td>0.182066</td><td>0.249848</td><td>0.15843</td><td>0.0</td><td>0.023042</td><td>0.311389</td><td>0.529966</td><td>0.490203</td><td>0.479312</td></tr><tr><td>2007</td><td>1966-11-25 02:02:00</td><td>0.24487</td><td>0.0</td><td>0.135282</td><td>0.064337</td><td>0.465084</td><td>0.336859</td><td>0.151743</td><td>0.729861</td><td>0.179161</td><td>0.0</td></tr><tr><td>5799</td><td>1967-09-19 12:31:00</td><td>0.192367</td><td>0.232332</td><td>0.283402</td><td>0.336952</td><td>0.0</td><td>0.176422</td><td>0.238416</td><td>0.646879</td><td>0.250217</td><td>0.382277</td></tr><tr><td>1319</td><td>1969-07-21 23:16:00</td><td>0.165635</td><td>0.200046</td><td>0.183015</td><td>0.261115</td><td>0.125837</td><td>0.151906</td><td>0.205285</td><td>0.759528</td><td>0.403961</td><td>0.098747</td></tr><tr><td>4234</td><td>1966-04-14 22:04:00</td><td>0.493461</td><td>0.119196</td><td>0.272619</td><td>0.207444</td><td>0.0</td><td>0.045256</td><td>0.183475</td><td>0.588324</td><td>0.433253</td><td>0.235349</td></tr></tbody></table></div>"
                        ],
                        "text/plain": [
                            "shape: (5, 12)\n",
                            "┌───────────┬────────────────┬──────────┬──────────┬───┬──────────┬──────────┬──────────┬──────────┐\n",
                            "│ entity_id ┆ timestamp      ┆ and      ┆ for      ┆ … ┆ that     ┆ the      ┆ to       ┆ was      │\n",
                            "│ ---       ┆ ---            ┆ ---      ┆ ---      ┆   ┆ ---      ┆ ---      ┆ ---      ┆ ---      │\n",
                            "│ i64       ┆ datetime[μs]   ┆ f64      ┆ f64      ┆   ┆ f64      ┆ f64      ┆ f64      ┆ f64      │\n",
                            "╞═══════════╪════════════════╪══════════╪══════════╪═══╪══════════╪══════════╪══════════╪══════════╡\n",
                            "│ 4647      ┆ 1967-07-19     ┆ 0.175872 ┆ 0.182066 ┆ … ┆ 0.311389 ┆ 0.529966 ┆ 0.490203 ┆ 0.479312 │\n",
                            "│           ┆ 00:22:00       ┆          ┆          ┆   ┆          ┆          ┆          ┆          │\n",
                            "│ 2007      ┆ 1966-11-25     ┆ 0.24487  ┆ 0.0      ┆ … ┆ 0.151743 ┆ 0.729861 ┆ 0.179161 ┆ 0.0      │\n",
                            "│           ┆ 02:02:00       ┆          ┆          ┆   ┆          ┆          ┆          ┆          │\n",
                            "│ 5799      ┆ 1967-09-19     ┆ 0.192367 ┆ 0.232332 ┆ … ┆ 0.238416 ┆ 0.646879 ┆ 0.250217 ┆ 0.382277 │\n",
                            "│           ┆ 12:31:00       ┆          ┆          ┆   ┆          ┆          ┆          ┆          │\n",
                            "│ 1319      ┆ 1969-07-21     ┆ 0.165635 ┆ 0.200046 ┆ … ┆ 0.205285 ┆ 0.759528 ┆ 0.403961 ┆ 0.098747 │\n",
                            "│           ┆ 23:16:00       ┆          ┆          ┆   ┆          ┆          ┆          ┆          │\n",
                            "│ 4234      ┆ 1966-04-14     ┆ 0.493461 ┆ 0.119196 ┆ … ┆ 0.183475 ┆ 0.588324 ┆ 0.433253 ┆ 0.235349 │\n",
                            "│           ┆ 22:04:00       ┆          ┆          ┆   ┆          ┆          ┆          ┆          │\n",
                            "└───────────┴────────────────┴──────────┴──────────┴───┴──────────┴──────────┴──────────┴──────────┘"
                        ]
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "embedded_text_with_metadata.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now that we have our embeddings in a dataframe including the `entity_id` and `timestamp`, we can simply pass it to `PredictorSpec`!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": [
                "import datetime as dt\n",
                "\n",
                "import numpy as np\n",
                "from timeseriesflattener import PredictorSpec, ValueFrame\n",
                "from timeseriesflattener.aggregators import MeanAggregator\n",
                "\n",
                "text_spec = PredictorSpec(\n",
                "    ValueFrame(\n",
                "        init_df=embedded_text_with_metadata,\n",
                "        entity_id_col_name=\"entity_id\",\n",
                "        value_timestamp_col_name=\"timestamp\",\n",
                "    ),\n",
                "    lookbehind_distances=[dt.timedelta(days=365), dt.timedelta(days=730)],\n",
                "    aggregators=[MeanAggregator()],\n",
                "    fallback=np.nan,\n",
                "    column_prefix=\"pred_tfidf\",\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's make some features! "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We are creating 10*2=20 features: 1 for each embedding for each lookbehind (365 and 730 days), using the mean aggregation function."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/au554730/Desktop/Projects/timeseriesflattener/.venv/lib/python3.9/site-packages/rich/live.py:231: \n",
                            "UserWarning: install \"ipywidgets\" for Jupyter support\n",
                            "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "/Users/au554730/Desktop/Projects/timeseriesflattener/.venv/lib/python3.9/site-packages/rich/live.py:231: \n",
                            "UserWarning: install \"ipywidgets\" for Jupyter support\n",
                            "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Processing spec: ['and', 'for', 'in', 'of', 'or', 'patient', 'that', 'the', 'to', 'was']\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "Processing spec: ['and', 'for', 'in', 'of', 'or', 'patient', 'that', 'the', 'to', 'was']\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
                        ],
                        "text/plain": []
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# make features how you would normally\n",
                "from timeseriesflattener import Flattener, PredictionTimeFrame\n",
                "from timeseriesflattener.testing.load_synth_data import load_synth_prediction_times\n",
                "\n",
                "flattener = Flattener(\n",
                "    predictiontime_frame=PredictionTimeFrame(\n",
                "        init_df=load_synth_prediction_times(),\n",
                "        entity_id_col_name=\"entity_id\",\n",
                "        timestamp_col_name=\"timestamp\",\n",
                "    )\n",
                ")\n",
                "\n",
                "df = flattener.aggregate_timeseries(specs=[text_spec]).df.collect()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's check the output."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div><style>\n",
                            ".dataframe > thead > tr,\n",
                            ".dataframe > tbody > tr {\n",
                            "  text-align: right;\n",
                            "  white-space: pre-wrap;\n",
                            "}\n",
                            "</style>\n",
                            "<small>shape: (5, 23)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>entity_id</th><th>timestamp</th><th>prediction_time_uuid</th><th>pred_tfidf_and_within_0_to_365_days_mean_fallback_nan</th><th>pred_tfidf_for_within_0_to_365_days_mean_fallback_nan</th><th>pred_tfidf_in_within_0_to_365_days_mean_fallback_nan</th><th>pred_tfidf_of_within_0_to_365_days_mean_fallback_nan</th><th>pred_tfidf_or_within_0_to_365_days_mean_fallback_nan</th><th>pred_tfidf_patient_within_0_to_365_days_mean_fallback_nan</th><th>pred_tfidf_that_within_0_to_365_days_mean_fallback_nan</th><th>pred_tfidf_the_within_0_to_365_days_mean_fallback_nan</th><th>pred_tfidf_to_within_0_to_365_days_mean_fallback_nan</th><th>pred_tfidf_was_within_0_to_365_days_mean_fallback_nan</th><th>pred_tfidf_and_within_0_to_730_days_mean_fallback_nan</th><th>pred_tfidf_for_within_0_to_730_days_mean_fallback_nan</th><th>pred_tfidf_in_within_0_to_730_days_mean_fallback_nan</th><th>pred_tfidf_of_within_0_to_730_days_mean_fallback_nan</th><th>pred_tfidf_or_within_0_to_730_days_mean_fallback_nan</th><th>pred_tfidf_patient_within_0_to_730_days_mean_fallback_nan</th><th>pred_tfidf_that_within_0_to_730_days_mean_fallback_nan</th><th>pred_tfidf_the_within_0_to_730_days_mean_fallback_nan</th><th>pred_tfidf_to_within_0_to_730_days_mean_fallback_nan</th><th>pred_tfidf_was_within_0_to_730_days_mean_fallback_nan</th></tr><tr><td>i64</td><td>datetime[μs]</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>1660</td><td>1968-08-04 02:05:00</td><td>&quot;1660-1968-08-0…</td><td>0.093117</td><td>0.028116</td><td>0.102888</td><td>0.146794</td><td>0.67206</td><td>0.298894</td><td>0.173111</td><td>0.55509</td><td>0.227099</td><td>0.16654</td><td>0.093117</td><td>0.028116</td><td>0.102888</td><td>0.146794</td><td>0.67206</td><td>0.298894</td><td>0.173111</td><td>0.55509</td><td>0.227099</td><td>0.16654</td></tr><tr><td>5570</td><td>1966-07-12 10:54:00</td><td>&quot;5570-1966-07-1…</td><td>0.611529</td><td>0.0</td><td>0.0</td><td>0.321347</td><td>0.0</td><td>0.280419</td><td>0.378958</td><td>0.280419</td><td>0.298286</td><td>0.364574</td><td>0.611529</td><td>0.0</td><td>0.0</td><td>0.321347</td><td>0.0</td><td>0.280419</td><td>0.378958</td><td>0.280419</td><td>0.298286</td><td>0.364574</td></tr><tr><td>7337</td><td>1966-06-28 10:34:00</td><td>&quot;7337-1966-06-2…</td><td>0.231068</td><td>0.139536</td><td>0.127656</td><td>0.303555</td><td>0.0</td><td>0.158935</td><td>0.071595</td><td>0.847656</td><td>0.225416</td><td>0.137755</td><td>0.231068</td><td>0.139536</td><td>0.127656</td><td>0.303555</td><td>0.0</td><td>0.158935</td><td>0.071595</td><td>0.847656</td><td>0.225416</td><td>0.137755</td></tr><tr><td>4234</td><td>1969-08-09 12:46:00</td><td>&quot;4234-1969-08-0…</td><td>0.493461</td><td>0.119196</td><td>0.272619</td><td>0.207444</td><td>0.0</td><td>0.045256</td><td>0.183475</td><td>0.588324</td><td>0.433253</td><td>0.235349</td><td>0.493461</td><td>0.119196</td><td>0.272619</td><td>0.207444</td><td>0.0</td><td>0.045256</td><td>0.183475</td><td>0.588324</td><td>0.433253</td><td>0.235349</td></tr><tr><td>5799</td><td>1966-12-15 08:15:00</td><td>&quot;5799-1966-12-1…</td><td>0.192367</td><td>0.232332</td><td>0.283402</td><td>0.336952</td><td>0.0</td><td>0.176422</td><td>0.238416</td><td>0.646879</td><td>0.250217</td><td>0.382277</td><td>0.192367</td><td>0.232332</td><td>0.283402</td><td>0.336952</td><td>0.0</td><td>0.176422</td><td>0.238416</td><td>0.646879</td><td>0.250217</td><td>0.382277</td></tr></tbody></table></div>"
                        ],
                        "text/plain": [
                            "shape: (5, 23)\n",
                            "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
                            "│ entity_id ┆ timestamp ┆ pred_time ┆ pred_tfid ┆ … ┆ pred_tfid ┆ pred_tfid ┆ pred_tfid ┆ pred_tfi │\n",
                            "│ ---       ┆ ---       ┆ _uuid     ┆ f_and_wit ┆   ┆ f_that_wi ┆ f_the_wit ┆ f_to_with ┆ df_was_w │\n",
                            "│ i64       ┆ datetime[ ┆ ---       ┆ hin_0_to_ ┆   ┆ thin_0_to ┆ hin_0_to_ ┆ in_0_to_7 ┆ ithin_0_ │\n",
                            "│           ┆ μs]       ┆ str       ┆ 365_d…    ┆   ┆ _730_…    ┆ 730_d…    ┆ 30_da…    ┆ to_730_d │\n",
                            "│           ┆           ┆           ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ …        │\n",
                            "│           ┆           ┆           ┆ f64       ┆   ┆ f64       ┆ f64       ┆ f64       ┆ ---      │\n",
                            "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ f64      │\n",
                            "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
                            "│ 1660      ┆ 1968-08-0 ┆ 1660-1968 ┆ 0.093117  ┆ … ┆ 0.173111  ┆ 0.55509   ┆ 0.227099  ┆ 0.16654  │\n",
                            "│           ┆ 4         ┆ -08-04    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
                            "│           ┆ 02:05:00  ┆ 02:05:00. ┆           ┆   ┆           ┆           ┆           ┆          │\n",
                            "│           ┆           ┆ 000000    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
                            "│ 5570      ┆ 1966-07-1 ┆ 5570-1966 ┆ 0.611529  ┆ … ┆ 0.378958  ┆ 0.280419  ┆ 0.298286  ┆ 0.364574 │\n",
                            "│           ┆ 2         ┆ -07-12    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
                            "│           ┆ 10:54:00  ┆ 10:54:00. ┆           ┆   ┆           ┆           ┆           ┆          │\n",
                            "│           ┆           ┆ 000000    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
                            "│ 7337      ┆ 1966-06-2 ┆ 7337-1966 ┆ 0.231068  ┆ … ┆ 0.071595  ┆ 0.847656  ┆ 0.225416  ┆ 0.137755 │\n",
                            "│           ┆ 8         ┆ -06-28    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
                            "│           ┆ 10:34:00  ┆ 10:34:00. ┆           ┆   ┆           ┆           ┆           ┆          │\n",
                            "│           ┆           ┆ 000000    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
                            "│ 4234      ┆ 1969-08-0 ┆ 4234-1969 ┆ 0.493461  ┆ … ┆ 0.183475  ┆ 0.588324  ┆ 0.433253  ┆ 0.235349 │\n",
                            "│           ┆ 9         ┆ -08-09    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
                            "│           ┆ 12:46:00  ┆ 12:46:00. ┆           ┆   ┆           ┆           ┆           ┆          │\n",
                            "│           ┆           ┆ 000000    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
                            "│ 5799      ┆ 1966-12-1 ┆ 5799-1966 ┆ 0.192367  ┆ … ┆ 0.238416  ┆ 0.646879  ┆ 0.250217  ┆ 0.382277 │\n",
                            "│           ┆ 5         ┆ -12-15    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
                            "│           ┆ 08:15:00  ┆ 08:15:00. ┆           ┆   ┆           ┆           ┆           ┆          │\n",
                            "│           ┆           ┆ 000000    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
                            "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
                        ]
                    },
                    "execution_count": 29,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import polars as pl\n",
                "import polars.selectors as cs\n",
                "\n",
                "# dropping na values in float columns (no embeddings within the lookbehind periods) for the sake of this example\n",
                "df.filter(pl.all_horizontal(cs.float().is_not_nan())).head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "And just like that, you're ready to make a prediction model!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.10.9 ('.venv': poetry)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.2"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "9e85d6a49b1f06126f30ca9ae16ded22dd7c17d2dbfabea9098dc6424f12e12a"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}

<!doctype html>
<html class="no-js" lang="en">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />
<meta property="og:title" content="Adding text features" />
<meta property="og:type" content="website" />
<meta property="og:url" content="tutorials/03_text.html" />
<meta property="og:site_name" content="timeseriesflattener" />
<meta property="og:description" content="So far, the tutorials have dealt with tabular data only. This tutorial will show you to make predictors out of text features, such as clinical notes, within timeseriesflattener. Specifically, this ..." />
<meta property="og:image:width" content="1146" />
<meta property="og:image:height" content="600" />
<meta property="og:image" content="/_images/social_previews/summary_tutorials_03_text_f323cf34.png" />
<meta property="og:image:alt" content="So far, the tutorials have dealt with tabular data only. This tutorial will show you to make predictors out of text features, such as clinical notes, within..." />
<meta name="description" content="So far, the tutorials have dealt with tabular data only. This tutorial will show you to make predictors out of text features, such as clinical notes, within timeseriesflattener. Specifically, this ..." />
<meta name="twitter:card" content="summary_large_image" />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="next" title="Frequently Asked Questions" href="../faq.html" /><link rel="prev" title="Advanced Tutorial" href="02_advanced.html" />

    <link rel="shortcut icon" href="../_static/favicon.ico"/><!-- Generated with Sphinx 7.1.2 and Furo 2023.03.27 -->
        <title>Adding text features - Timeseriesflattener</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=362ab14a" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?digest=fad236701ea90a88636c2a8c73b44ae642ed2a53" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css?v=6ad1a40c" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?digest=30d1aed668e5c3a91c3e3bf6a60b675221979f0e" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  --color-brand-primary: #ff5454;
  --color-brand-content: #ff7575;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  --color-brand-primary: #ff8f8f;
  --color-brand-content: #ff8f8f;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  --color-brand-primary: #ff8f8f;
  --color-brand-content: #ff8f8f;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">Timeseriesflattener</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo only-light" src="../_static/icon.png" alt="Light Logo"/>
    <img class="sidebar-logo only-dark" src="../_static/icon_dark.png" alt="Dark Logo"/>
  </div>
  
  <span class="sidebar-brand-text">Timeseriesflattener</span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Getting started</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1 current has-children"><a class="reference internal" href="../tutorials.html">Tutorials</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="01_basic.html">Introductory Tutorial</a></li>
<li class="toctree-l2"><a class="reference internal" href="02_advanced.html">Advanced Tutorial</a></li>
<li class="toctree-l2 current current-page"><a class="current reference internal" href="#">Adding text features</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">Frequently Asked Questions</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../feature_specifications.html">Feature specifications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../timeseriesflattener.html">Timeseriesflattener</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Changelog</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://github.com/Aarhus-Psychiatry-Research/timeseriesflattener/blob/main/CHANGELOG.md">Changelog</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">GitHub</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://github.com/Aarhus-Psychiatry-Research/timeseriesflattener">GitHub Repository</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="edit-this-page">
  <a class="muted-link" href="https://github.com/Aarhus-Psychiatry-Research/timeseriesflattener/edit/main/docs/tutorials/03_text.ipynb" title="Edit this page">
    <svg aria-hidden="true" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <path d="M4 20h4l10.5 -10.5a1.5 1.5 0 0 0 -4 -4l-10.5 10.5v4" />
      <line x1="13.5" y1="6.5" x2="17.5" y2="10.5" />
    </svg>
    <span class="visually-hidden">Edit this page</span>
  </a>
</div><div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <section id="adding-text-features">
<h1>Adding text features<a class="headerlink" href="#adding-text-features" title="Permalink to this heading">#</a></h1>
<p>So far, the tutorials have dealt with <em>tabular</em> data only. This tutorial will show you to make predictors out of text features, such as clinical notes, within <code class="docutils literal notranslate"><span class="pre">timeseriesflattener</span></code>.</p>
<p>Specifically, this tutorial will cover:</p>
<ol class="arabic simple">
<li><p>How to generate flattened predictors from already embedded text.</p></li>
<li><p>How to featurize text using Huggingface or sci-kit learn models.</p></li>
<li><p>How to use write your own text embedding function in <code class="docutils literal notranslate"><span class="pre">timeseriesflattener</span></code>.</p></li>
</ol>
<p>To use the features in this tutorial you’ll need to install some extra dependencies. These can be installed by running:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">pytorch</span> <span class="n">transformers</span> <span class="n">sentence</span><span class="o">-</span><span class="n">transformer</span>
</pre></div>
</div>
<p>or by installing <code class="docutils literal notranslate"><span class="pre">timeseriesflattener</span></code> with the text dependencies.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">timeseriesflattener</span><span class="s2">&quot;[text]&quot;</span>
</pre></div>
</div>
<section id="the-dataset">
<h2>The dataset<a class="headerlink" href="#the-dataset" title="Permalink to this heading">#</a></h2>
<p>To start out, let’s load a synthetic dataset containing text. As with all other features, each row in the dataset needs an ID, a timestamp, and the feature value.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">timeseriesflattener.testing.load_synth_data</span> <span class="kn">import</span> <span class="n">load_synth_text</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/runner/.local/lib/python3.10/site-packages/pydantic/_internal/_config.py:269: UserWarning: Valid config keys have changed in V2:
* &#39;allow_mutation&#39; has been removed
  warnings.warn(message, UserWarning)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">synth_text</span> <span class="o">=</span> <span class="n">load_synth_text</span><span class="p">()</span>
<span class="n">synth_text</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>entity_id</th>
      <th>timestamp</th>
      <th>value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>4647</td>
      <td>1967-07-19 00:22:00</td>
      <td>The patient went into a medically induced coma...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2007</td>
      <td>1966-11-25 02:02:00</td>
      <td>The patient is taken to the emergency departme...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5799</td>
      <td>1967-09-19 12:31:00</td>
      <td>The patient, described as a 7-month old son wh...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1319</td>
      <td>1969-07-21 23:16:00</td>
      <td>The patient had been left on a bed for 20 minu...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4234</td>
      <td>1966-04-14 22:04:00</td>
      <td>The patient had had some severe allergies but ...</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
<section id="generating-predictors-from-embedded-text">
<h2>Generating predictors from embedded text<a class="headerlink" href="#generating-predictors-from-embedded-text" title="Permalink to this heading">#</a></h2>
<p>As generating text embeddings can often take a while, it can be an advantageous to embed the text before using <code class="docutils literal notranslate"><span class="pre">timeseriesflattener</span></code> to speed up the computation if you’re generating multiple datasets. This first block will show how to convert a dataframe with embeddings into a format that can be passed to <code class="docutils literal notranslate"><span class="pre">timeseriesflattener</span></code>. Skip to <span class="xref myst">TextPredictorSpec</span> if you want to perform the embedding step directly in <code class="docutils literal notranslate"><span class="pre">timeseriesflattener</span></code>.</p>
<p>To start, let’s embed the synthetic text data using a sentence-transformer. You can use any form of text-embedding you want - the only constraint is that the result of the embedding function should be a dataframe with an <code class="docutils literal notranslate"><span class="pre">entitiy_id_col</span></code>, <code class="docutils literal notranslate"><span class="pre">timestamp_col</span></code> and any number of <code class="docutils literal notranslate"><span class="pre">value_cols</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%capture</span>
<span class="kn">from</span> <span class="nn">sentence_transformers</span> <span class="kn">import</span> <span class="n">SentenceTransformer</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1"># load fast model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">SentenceTransformer</span><span class="p">(</span><span class="s2">&quot;all-MiniLM-L6-v2&quot;</span><span class="p">)</span>

<span class="c1"># define function to embed text and return a dataframe</span>
<span class="k">def</span> <span class="nf">embed_text_to_df</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">SentenceTransformer</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
    <span class="n">embeddings</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">embeddings</span><span class="p">)</span>

<span class="c1"># embed text</span>
<span class="n">embedded_text</span> <span class="o">=</span> <span class="n">embed_text_to_df</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="n">synth_text</span><span class="p">[</span><span class="s2">&quot;value&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
<span class="c1"># drop the text column from the original dataframe</span>
<span class="n">metadata_only</span> <span class="o">=</span> <span class="n">synth_text</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;value&quot;</span><span class="p">])</span>
<span class="c1"># concatenate the metadata and the embedded text</span>
<span class="n">embedded_text_with_metadata</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">metadata_only</span><span class="p">,</span> <span class="n">embedded_text</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">embedded_text_with_metadata</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>entity_id</th>
      <th>timestamp</th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>...</th>
      <th>374</th>
      <th>375</th>
      <th>376</th>
      <th>377</th>
      <th>378</th>
      <th>379</th>
      <th>380</th>
      <th>381</th>
      <th>382</th>
      <th>383</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>4647</td>
      <td>1967-07-19 00:22:00</td>
      <td>-0.020159</td>
      <td>0.006134</td>
      <td>-0.006454</td>
      <td>0.005938</td>
      <td>0.038562</td>
      <td>0.005949</td>
      <td>-0.056681</td>
      <td>0.029464</td>
      <td>...</td>
      <td>0.021432</td>
      <td>0.061494</td>
      <td>0.011665</td>
      <td>0.018157</td>
      <td>-0.035946</td>
      <td>0.101041</td>
      <td>-0.002912</td>
      <td>0.014489</td>
      <td>-0.033684</td>
      <td>-0.085988</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2007</td>
      <td>1966-11-25 02:02:00</td>
      <td>-0.065502</td>
      <td>0.026975</td>
      <td>-0.042235</td>
      <td>-0.012499</td>
      <td>-0.012820</td>
      <td>-0.003107</td>
      <td>0.025823</td>
      <td>0.115787</td>
      <td>...</td>
      <td>-0.013681</td>
      <td>-0.008509</td>
      <td>-0.005801</td>
      <td>-0.019228</td>
      <td>-0.029137</td>
      <td>0.107618</td>
      <td>0.027575</td>
      <td>0.061189</td>
      <td>-0.036197</td>
      <td>-0.023715</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5799</td>
      <td>1967-09-19 12:31:00</td>
      <td>-0.015965</td>
      <td>0.030239</td>
      <td>-0.025726</td>
      <td>0.011575</td>
      <td>-0.056353</td>
      <td>0.024950</td>
      <td>0.005075</td>
      <td>0.158615</td>
      <td>...</td>
      <td>0.021345</td>
      <td>0.019185</td>
      <td>0.046376</td>
      <td>0.008546</td>
      <td>-0.017712</td>
      <td>0.014252</td>
      <td>-0.090198</td>
      <td>0.036281</td>
      <td>0.119648</td>
      <td>-0.031743</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1319</td>
      <td>1969-07-21 23:16:00</td>
      <td>0.049595</td>
      <td>0.124481</td>
      <td>-0.050134</td>
      <td>0.036343</td>
      <td>0.040793</td>
      <td>0.067932</td>
      <td>0.108808</td>
      <td>0.068143</td>
      <td>...</td>
      <td>0.041999</td>
      <td>-0.011297</td>
      <td>0.013209</td>
      <td>0.002157</td>
      <td>-0.032716</td>
      <td>-0.001036</td>
      <td>-0.013384</td>
      <td>-0.025948</td>
      <td>-0.033742</td>
      <td>-0.013560</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4234</td>
      <td>1966-04-14 22:04:00</td>
      <td>-0.062923</td>
      <td>0.062385</td>
      <td>-0.048646</td>
      <td>0.081368</td>
      <td>0.115612</td>
      <td>-0.036585</td>
      <td>0.105179</td>
      <td>0.034068</td>
      <td>...</td>
      <td>0.015677</td>
      <td>-0.009112</td>
      <td>-0.032549</td>
      <td>0.021608</td>
      <td>-0.043334</td>
      <td>0.057872</td>
      <td>-0.044645</td>
      <td>0.024808</td>
      <td>0.002562</td>
      <td>0.030407</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 386 columns</p>
</div></div></div>
</div>
<p>Now that we have our embeddings, we can use the <code class="docutils literal notranslate"><span class="pre">df_with_multiple_values_to_named_dataframes</span></code> function to turn the embeddings into a format that can be readily supplied to <code class="docutils literal notranslate"><span class="pre">PredictorGroupSpec</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">timeseriesflattener.df_transforms</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">df_with_multiple_values_to_named_dataframes</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># split the dataframe into a list of named dataframes with one value each</span>
<span class="n">embedded_dfs</span> <span class="o">=</span> <span class="n">df_with_multiple_values_to_named_dataframes</span><span class="p">(</span>
    <span class="n">df</span><span class="o">=</span><span class="n">embedded_text_with_metadata</span><span class="p">,</span>
    <span class="n">entity_id_col_name</span><span class="o">=</span><span class="s2">&quot;entity_id&quot;</span><span class="p">,</span>
    <span class="n">timestamp_col_name</span><span class="o">=</span><span class="s2">&quot;timestamp&quot;</span><span class="p">,</span>
    <span class="n">name_prefix</span><span class="o">=</span><span class="s2">&quot;sent_emb_&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># check the first dataframe</span>
<span class="n">embedded_dfs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>entity_id</th>
      <th>timestamp</th>
      <th>value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>4647</td>
      <td>1967-07-19 00:22:00</td>
      <td>-0.020159</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2007</td>
      <td>1966-11-25 02:02:00</td>
      <td>-0.065502</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5799</td>
      <td>1967-09-19 12:31:00</td>
      <td>-0.015965</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1319</td>
      <td>1969-07-21 23:16:00</td>
      <td>0.049595</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4234</td>
      <td>1966-04-14 22:04:00</td>
      <td>-0.062923</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># check the number of embeddings/dataframes</span>
<span class="nb">len</span><span class="p">(</span><span class="n">embedded_dfs</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>384
</pre></div>
</div>
</div>
</div>
<p>Each dataframe has been named according to <code class="docutils literal notranslate"><span class="pre">name_prefix</span></code> and the column name. This means, that if your column names are informative (e.g. if they correspond to specific words in a BOW model) they will be kept.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">embedded_dfs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;sent_emb_0&#39;
</pre></div>
</div>
</div>
</div>
<p>Let’s make some features!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">timeseriesflattener.aggregation_fns</span> <span class="kn">import</span> <span class="n">mean</span>
<span class="kn">from</span> <span class="nn">timeseriesflattener.feature_specs.group_specs</span> <span class="kn">import</span> <span class="n">PredictorGroupSpec</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># create a group spec for the embedded text that will take the mean of each embedding on the column axis</span>
<span class="c1"># for the last 365 and 730 days</span>
<span class="n">emb_spec_batch</span> <span class="o">=</span> <span class="n">PredictorGroupSpec</span><span class="p">(</span>
    <span class="n">named_dataframes</span><span class="o">=</span><span class="n">embedded_dfs</span><span class="p">,</span>
    <span class="n">lookbehind_days</span><span class="o">=</span><span class="p">[</span><span class="mi">365</span><span class="p">,</span> <span class="mi">730</span><span class="p">],</span>
    <span class="n">fallback</span><span class="o">=</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">],</span>
    <span class="n">aggregation_fns</span><span class="o">=</span><span class="p">[</span><span class="n">mean</span><span class="p">],</span>
<span class="p">)</span><span class="o">.</span><span class="n">create_combinations</span><span class="p">()</span>

<span class="c1"># print the number of features we will create</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">emb_spec_batch</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>768
</pre></div>
</div>
</div>
</div>
<p>We are creating 384*2=768 features: 1 for each embedding for each lookbehind (365 and 730 days).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># make features how you would normally</span>
<span class="kn">from</span> <span class="nn">timeseriesflattener</span> <span class="kn">import</span> <span class="n">TimeseriesFlattener</span>
<span class="kn">from</span> <span class="nn">timeseriesflattener.testing.load_synth_data</span> <span class="kn">import</span> <span class="n">load_synth_prediction_times</span>

<span class="n">ts_flattener</span> <span class="o">=</span> <span class="n">TimeseriesFlattener</span><span class="p">(</span>
    <span class="n">prediction_times_df</span><span class="o">=</span><span class="n">load_synth_prediction_times</span><span class="p">(),</span>
    <span class="n">entity_id_col_name</span><span class="o">=</span><span class="s2">&quot;entity_id&quot;</span><span class="p">,</span>
    <span class="n">timestamp_col_name</span><span class="o">=</span><span class="s2">&quot;timestamp&quot;</span><span class="p">,</span>
    <span class="n">n_workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">drop_pred_times_with_insufficient_look_distance</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">ts_flattener</span><span class="o">.</span><span class="n">add_spec</span><span class="p">(</span><span class="n">emb_spec_batch</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">ts_flattener</span><span class="o">.</span><span class="n">get_df</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2023-08-02 09:16:54 [INFO] There were unprocessed specs, computing...
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2023-08-02 09:16:54 [INFO] Processing 768 temporal features in parallel with 1 workers. Chunksize is 768. If this is above 1, it may take some time for the progress bar to move, as processing is batched. However, this makes for much faster total performance.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  0%|          | 0/768 [00:00&lt;?, ?it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  0%|          | 1/768 [00:25&lt;5:26:48, 25.57s/it]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████| 768/768 [00:25&lt;00:00, 30.04it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2023-08-02 09:17:20 [INFO] Checking alignment of dataframes - this might take a little while (~2 minutes for 1.000 dataframes with 2.000.000 rows).
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2023-08-02 09:17:20 [INFO] Starting concatenation. Will take some time on performant systems, e.g. 30s for 100 features and 2_000_000 prediction times. This is normal.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2023-08-02 09:17:21 [INFO] Concatenation took 1.714 seconds
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2023-08-02 09:17:21 [INFO] Merging with original df
</pre></div>
</div>
</div>
</div>
<p>Let’s check the output.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># dropping na values (no embeddings within the lookbehind period) for the sake of this example</span>
<span class="n">df</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>entity_id</th>
      <th>timestamp</th>
      <th>prediction_time_uuid</th>
      <th>pred_sent_emb_25_within_730_days_mean_fallback_nan</th>
      <th>pred_sent_emb_344_within_365_days_mean_fallback_nan</th>
      <th>pred_sent_emb_368_within_365_days_mean_fallback_nan</th>
      <th>pred_sent_emb_125_within_365_days_mean_fallback_nan</th>
      <th>pred_sent_emb_193_within_730_days_mean_fallback_nan</th>
      <th>pred_sent_emb_308_within_730_days_mean_fallback_nan</th>
      <th>pred_sent_emb_113_within_365_days_mean_fallback_nan</th>
      <th>...</th>
      <th>pred_sent_emb_14_within_730_days_mean_fallback_nan</th>
      <th>pred_sent_emb_265_within_730_days_mean_fallback_nan</th>
      <th>pred_sent_emb_77_within_365_days_mean_fallback_nan</th>
      <th>pred_sent_emb_144_within_365_days_mean_fallback_nan</th>
      <th>pred_sent_emb_101_within_365_days_mean_fallback_nan</th>
      <th>pred_sent_emb_0_within_365_days_mean_fallback_nan</th>
      <th>pred_sent_emb_233_within_365_days_mean_fallback_nan</th>
      <th>pred_sent_emb_142_within_365_days_mean_fallback_nan</th>
      <th>pred_sent_emb_354_within_365_days_mean_fallback_nan</th>
      <th>pred_sent_emb_120_within_365_days_mean_fallback_nan</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1917</th>
      <td>4977</td>
      <td>1968-11-28 16:05:00</td>
      <td>4977-1968-11-28-16-05-00</td>
      <td>0.017894</td>
      <td>-0.029661</td>
      <td>-0.021868</td>
      <td>-0.006170</td>
      <td>-0.051786</td>
      <td>-0.053086</td>
      <td>-0.040660</td>
      <td>...</td>
      <td>-0.012076</td>
      <td>0.029114</td>
      <td>-0.052350</td>
      <td>-0.081266</td>
      <td>0.037202</td>
      <td>0.029870</td>
      <td>-0.044642</td>
      <td>-0.094985</td>
      <td>0.058408</td>
      <td>0.052193</td>
    </tr>
    <tr>
      <th>2463</th>
      <td>6840</td>
      <td>1965-11-02 07:17:00</td>
      <td>6840-1965-11-02-07-17-00</td>
      <td>0.032056</td>
      <td>-0.017802</td>
      <td>-0.020317</td>
      <td>-0.003878</td>
      <td>-0.068410</td>
      <td>-0.024626</td>
      <td>0.002075</td>
      <td>...</td>
      <td>-0.058417</td>
      <td>0.095710</td>
      <td>0.014129</td>
      <td>-0.002630</td>
      <td>-0.008826</td>
      <td>0.090487</td>
      <td>-0.004694</td>
      <td>-0.046674</td>
      <td>-0.006335</td>
      <td>-0.028022</td>
    </tr>
    <tr>
      <th>2580</th>
      <td>18</td>
      <td>1968-08-26 15:19:00</td>
      <td>18-1968-08-26-15-19-00</td>
      <td>0.006431</td>
      <td>0.004501</td>
      <td>-0.006279</td>
      <td>-0.015985</td>
      <td>-0.069001</td>
      <td>-0.055356</td>
      <td>-0.000762</td>
      <td>...</td>
      <td>0.021304</td>
      <td>-0.057196</td>
      <td>-0.022070</td>
      <td>-0.050446</td>
      <td>-0.001568</td>
      <td>-0.002633</td>
      <td>0.025319</td>
      <td>-0.110229</td>
      <td>-0.031532</td>
      <td>0.004718</td>
    </tr>
    <tr>
      <th>2741</th>
      <td>9832</td>
      <td>1969-06-03 04:36:00</td>
      <td>9832-1969-06-03-04-36-00</td>
      <td>0.094799</td>
      <td>0.013455</td>
      <td>0.070465</td>
      <td>0.066168</td>
      <td>-0.012171</td>
      <td>-0.033816</td>
      <td>-0.024770</td>
      <td>...</td>
      <td>-0.078805</td>
      <td>-0.036647</td>
      <td>-0.022788</td>
      <td>0.020711</td>
      <td>0.066916</td>
      <td>-0.020382</td>
      <td>-0.071360</td>
      <td>-0.112359</td>
      <td>-0.020004</td>
      <td>-0.033745</td>
    </tr>
    <tr>
      <th>2931</th>
      <td>7281</td>
      <td>1967-06-05 00:41:00</td>
      <td>7281-1967-06-05-00-41-00</td>
      <td>0.030327</td>
      <td>0.055882</td>
      <td>0.024312</td>
      <td>-0.014444</td>
      <td>-0.055627</td>
      <td>-0.016736</td>
      <td>-0.072137</td>
      <td>...</td>
      <td>-0.050149</td>
      <td>-0.009907</td>
      <td>-0.031844</td>
      <td>0.037615</td>
      <td>-0.030904</td>
      <td>0.002086</td>
      <td>0.009941</td>
      <td>-0.085689</td>
      <td>-0.013160</td>
      <td>0.010426</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 771 columns</p>
</div></div></div>
</div>
</section>
<section id="textpredictorspec">
<h2>TextPredictorSpec<a class="headerlink" href="#textpredictorspec" title="Permalink to this heading">#</a></h2>
<p>The main difference when specifying text predictors compared to tabular predictors is the <code class="docutils literal notranslate"><span class="pre">Spec</span></code> you define. When working directly with text, we need to specify a <code class="docutils literal notranslate"><span class="pre">TextPredictorSpec</span></code> which is entirely similar to the <code class="docutils literal notranslate"><span class="pre">PredictorSpec</span></code> except for two additional attributes: <code class="docutils literal notranslate"><span class="pre">embedding_fn</span></code> and <code class="docutils literal notranslate"><span class="pre">embedding_fn_kwargs</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">embedding_fn</span></code> should be a callable that takes a pandas Series containing text and converts it to a pandas DataFrame with a column for each feature. <code class="docutils literal notranslate"><span class="pre">embedding_fn_kwargs</span></code> are simply optional keyword arguments that will be passed to the embedding function, such as a Huggingface model name.</p>
<p>Not all <code class="docutils literal notranslate"><span class="pre">resolve_multiple_fn</span></code> are meaningful for text, as we can’t do numerical operations on text. Instead, <code class="docutils literal notranslate"><span class="pre">TextPredictorSpec</span></code> defaults to the “concatenate” option, which simply concatenates all texts within the lookbehind within. Other options that work for text are “latest” and “earliest”.</p>
<section id="featurization-using-sentence-transformers">
<h3>Featurization using sentence-transformers<a class="headerlink" href="#featurization-using-sentence-transformers" title="Permalink to this heading">#</a></h3>
<p>Let’s specify a <code class="docutils literal notranslate"><span class="pre">TextPredictorSpec</span></code> using a <a class="reference external" href="https://www.sbert.net/">sentence-transformers</a> model. <code class="docutils literal notranslate"><span class="pre">timeseriesflattener</span></code> includes functions that make it easy to featurize text using either sentence-transformers or any text model from the <a class="reference external" href="https://huggingface.co/">Huggingface Hub</a>.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">sentence_transformers_embedding</span></code> function is recommended for sentence-transformers. If you want to another type of model from the Huggingface Hub we recommend using the <code class="docutils literal notranslate"><span class="pre">huggingface_embedding</span></code> function which has the same interface as <code class="docutils literal notranslate"><span class="pre">sentence_transformers_embedding</span></code>.</p>
<p>Notice, both <code class="docutils literal notranslate"><span class="pre">huggingface_embedding</span></code> and <code class="docutils literal notranslate"><span class="pre">sentence_transformers_embedding</span></code> will truncate the input to the maximum sequence length allowed by the model. If you want to use Huggingface embeddings for larger blocks of text, either use the <code class="docutils literal notranslate"><span class="pre">sklearn_embedding</span></code> function or write your own embedding function (see below).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">timeseriesflattener.text_embedding_functions</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">sentence_transformers_embedding</span><span class="p">,</span>
    <span class="n">huggingface_embedding</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">timeseriesflattener</span> <span class="kn">import</span> <span class="n">TextPredictorSpec</span>
<span class="kn">from</span> <span class="nn">timeseriesflattener.aggregation_fns</span> <span class="kn">import</span> <span class="n">concatenate</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">text_spec</span> <span class="o">=</span> <span class="n">TextPredictorSpec</span><span class="p">(</span>
    <span class="n">timeseries_df</span><span class="o">=</span><span class="n">load_synth_text</span><span class="p">(),</span>
    <span class="n">lookbehind_days</span><span class="o">=</span><span class="mi">730</span><span class="p">,</span>
    <span class="n">fallback</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span>
    <span class="n">aggregation_fn</span><span class="o">=</span><span class="n">concatenate</span><span class="p">,</span>
    <span class="n">feature_base_name</span><span class="o">=</span><span class="s2">&quot;text-st&quot;</span><span class="p">,</span>
    <span class="n">embedding_fn</span><span class="o">=</span><span class="n">sentence_transformers_embedding</span><span class="p">,</span>
    <span class="n">embedding_fn_kwargs</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;model_name&quot;</span><span class="p">:</span> <span class="s2">&quot;sentence-transformers/all-MiniLM-L6-v2&quot;</span>
    <span class="p">},</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>That’s it. Let’s make our features in the usual way.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ts_flattener</span> <span class="o">=</span> <span class="n">TimeseriesFlattener</span><span class="p">(</span>
    <span class="n">prediction_times_df</span><span class="o">=</span><span class="n">load_synth_prediction_times</span><span class="p">(),</span>
    <span class="n">entity_id_col_name</span><span class="o">=</span><span class="s2">&quot;entity_id&quot;</span><span class="p">,</span>
    <span class="n">timestamp_col_name</span><span class="o">=</span><span class="s2">&quot;timestamp&quot;</span><span class="p">,</span>
    <span class="n">n_workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">drop_pred_times_with_insufficient_look_distance</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">ts_flattener</span><span class="o">.</span><span class="n">add_spec</span><span class="p">(</span><span class="n">text_spec</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">ts_flattener</span><span class="o">.</span><span class="n">get_df</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2023-08-02 09:17:22 [INFO] There were unprocessed specs, computing...
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2023-08-02 09:17:22 [INFO] Processing 1 temporal features in parallel with 1 workers. Chunksize is 1. If this is above 1, it may take some time for the progress bar to move, as processing is batched. However, this makes for much faster total performance.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  0%|          | 0/1 [00:00&lt;?, ?it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2023-08-02 09:17:22 [INFO] Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  0%|          | 0/1 [00:29&lt;?, ?it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</div>
<p>Let’s check the features.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>entity_id</th>
      <th>timestamp</th>
      <th>prediction_time_uuid</th>
      <th>pred_text-st-0_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-st-1_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-st-2_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-st-3_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-st-4_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-st-5_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-st-6_within_730_days_concatenate_fallback_nan</th>
      <th>...</th>
      <th>pred_text-st-374_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-st-375_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-st-376_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-st-377_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-st-378_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-st-379_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-st-380_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-st-381_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-st-382_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-st-383_within_730_days_concatenate_fallback_nan</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>9903</td>
      <td>1968-05-09 21:24:00</td>
      <td>9903-1968-05-09-21-24-00</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>7465</td>
      <td>1966-05-24 01:23:00</td>
      <td>7465-1966-05-24-01-23-00</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>6447</td>
      <td>1967-09-25 18:08:00</td>
      <td>6447-1967-09-25-18-08-00</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2121</td>
      <td>1966-05-05 20:52:00</td>
      <td>2121-1966-05-05-20-52-00</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4927</td>
      <td>1968-06-30 12:13:00</td>
      <td>4927-1968-06-30-12-13-00</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 387 columns</p>
</div></div></div>
</div>
<p>Because the synthetic text data is much smaller than the prediction times data, there are a lot of NaNs. Let’s subset to only see the prediction times that actually include text.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_pred_times_with_text</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span>
    <span class="o">~</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;pred_text-st-1_within_730_days_concatenate_fallback_nan&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span>
<span class="p">]</span>
<span class="n">df_pred_times_with_text</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>entity_id</th>
      <th>timestamp</th>
      <th>prediction_time_uuid</th>
      <th>pred_text-st-0_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-st-1_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-st-2_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-st-3_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-st-4_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-st-5_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-st-6_within_730_days_concatenate_fallback_nan</th>
      <th>...</th>
      <th>pred_text-st-374_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-st-375_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-st-376_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-st-377_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-st-378_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-st-379_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-st-380_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-st-381_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-st-382_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-st-383_within_730_days_concatenate_fallback_nan</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>244</th>
      <td>7337</td>
      <td>1966-06-28 10:34:00</td>
      <td>7337-1966-06-28-10-34-00</td>
      <td>-0.032579</td>
      <td>0.117177</td>
      <td>-0.049458</td>
      <td>0.009333</td>
      <td>0.013606</td>
      <td>0.021374</td>
      <td>0.001354</td>
      <td>...</td>
      <td>-0.017522</td>
      <td>0.099060</td>
      <td>0.049743</td>
      <td>0.015571</td>
      <td>-0.019073</td>
      <td>0.109147</td>
      <td>0.047269</td>
      <td>-0.043760</td>
      <td>0.020477</td>
      <td>-0.007479</td>
    </tr>
    <tr>
      <th>755</th>
      <td>8951</td>
      <td>1969-12-22 16:32:00</td>
      <td>8951-1969-12-22-16-32-00</td>
      <td>-0.011282</td>
      <td>0.002961</td>
      <td>0.025957</td>
      <td>-0.015063</td>
      <td>-0.050311</td>
      <td>0.048773</td>
      <td>-0.002749</td>
      <td>...</td>
      <td>-0.067139</td>
      <td>0.049532</td>
      <td>-0.030149</td>
      <td>-0.009194</td>
      <td>-0.051574</td>
      <td>0.013600</td>
      <td>-0.100028</td>
      <td>-0.116557</td>
      <td>0.033871</td>
      <td>0.008424</td>
    </tr>
    <tr>
      <th>896</th>
      <td>2007</td>
      <td>1968-10-15 14:12:00</td>
      <td>2007-1968-10-15-14-12-00</td>
      <td>-0.065502</td>
      <td>0.026975</td>
      <td>-0.042235</td>
      <td>-0.012499</td>
      <td>-0.012820</td>
      <td>-0.003107</td>
      <td>0.025823</td>
      <td>...</td>
      <td>-0.013681</td>
      <td>-0.008509</td>
      <td>-0.005801</td>
      <td>-0.019228</td>
      <td>-0.029137</td>
      <td>0.107618</td>
      <td>0.027575</td>
      <td>0.061189</td>
      <td>-0.036197</td>
      <td>-0.023715</td>
    </tr>
    <tr>
      <th>1517</th>
      <td>1728</td>
      <td>1968-05-29 12:27:00</td>
      <td>1728-1968-05-29-12-27-00</td>
      <td>0.003414</td>
      <td>-0.022889</td>
      <td>0.003017</td>
      <td>0.036401</td>
      <td>0.021559</td>
      <td>-0.004627</td>
      <td>0.070992</td>
      <td>...</td>
      <td>-0.010578</td>
      <td>0.028139</td>
      <td>-0.013348</td>
      <td>-0.062894</td>
      <td>-0.059819</td>
      <td>-0.064517</td>
      <td>0.013139</td>
      <td>-0.030818</td>
      <td>0.088636</td>
      <td>0.012063</td>
    </tr>
    <tr>
      <th>1917</th>
      <td>4977</td>
      <td>1968-11-28 16:05:00</td>
      <td>4977-1968-11-28-16-05-00</td>
      <td>0.029870</td>
      <td>0.059029</td>
      <td>0.025774</td>
      <td>0.065304</td>
      <td>0.001232</td>
      <td>0.097216</td>
      <td>0.005217</td>
      <td>...</td>
      <td>-0.078040</td>
      <td>0.121744</td>
      <td>-0.002166</td>
      <td>0.040929</td>
      <td>-0.075126</td>
      <td>-0.069748</td>
      <td>0.009481</td>
      <td>0.039800</td>
      <td>0.010281</td>
      <td>0.028113</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 387 columns</p>
</div></div></div>
</div>
</section>
<section id="featurization-using-sklearn-models">
<h3>Featurization using sklearn models<a class="headerlink" href="#featurization-using-sklearn-models" title="Permalink to this heading">#</a></h3>
<p>If you want to embed your model using an sklearn model using e.g. TF-IDF, this can also be easily accomplished. First, you should train the sklearn model (e.g. <code class="docutils literal notranslate"><span class="pre">TfidfVectorizer</span></code>) on your dataset (using the <code class="docutils literal notranslate"><span class="pre">.fit</span></code> method).</p>
<p>Now, to use your trained model in <code class="docutils literal notranslate"><span class="pre">timeseriesflattener</span></code>, simply use the <code class="docutils literal notranslate"><span class="pre">sklearn_embedding</span></code> function and supply the model as an embedding function keyword argument.</p>
<p>In the following example we will use a simple CountVectorizer model, which has been pretrained on the synthetic data, to create the predictors.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">timeseriesflattener.text_embedding_functions</span> <span class="kn">import</span> <span class="n">sklearn_embedding</span>
<span class="kn">from</span> <span class="nn">timeseriesflattener.testing.text_embedding_functions</span> <span class="kn">import</span> <span class="n">_load_bow_model</span>

<span class="n">tfidf_model</span> <span class="o">=</span> <span class="n">_load_bow_model</span><span class="p">()</span>
<span class="n">tfidf_model</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/au554730/Desktop/Projects/timeseriesflattener/.venv/lib/python3.10/site-packages/sklearn/base.py:299: UserWarning: Trying to unpickle estimator CountVectorizer from version 1.1.2 when using version 1.2.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:
https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations
  warnings.warn(
</pre></div>
</div>
<div class="output text_html"><style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>CountVectorizer(max_features=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" checked><label for="sk-estimator-id-1" class="sk-toggleable__label sk-toggleable__label-arrow">CountVectorizer</label><div class="sk-toggleable__content"><pre>CountVectorizer(max_features=10)</pre></div></div></div></div></div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">count_vectorizer_text_spec</span> <span class="o">=</span> <span class="n">TextPredictorSpec</span><span class="p">(</span>
    <span class="n">timeseries_df</span><span class="o">=</span><span class="n">load_synth_text</span><span class="p">(),</span>
    <span class="n">lookbehind_days</span><span class="o">=</span><span class="mi">730</span><span class="p">,</span>
    <span class="n">fallback</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span>
    <span class="n">aggregation_fn</span><span class="o">=</span><span class="n">concatenate</span><span class="p">,</span>
    <span class="n">feature_base_name</span><span class="o">=</span><span class="s2">&quot;text-cv&quot;</span><span class="p">,</span>
    <span class="n">embedding_fn</span><span class="o">=</span><span class="n">sklearn_embedding</span><span class="p">,</span>
    <span class="n">embedding_fn_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="n">tfidf_model</span><span class="p">},</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s add the feature to the dataset:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ts_flattener</span><span class="o">.</span><span class="n">add_spec</span><span class="p">(</span><span class="n">count_vectorizer_text_spec</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">ts_flattener</span><span class="o">.</span><span class="n">get_df</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2023-07-21 14:58:40 [INFO] There were unprocessed specs, computing...
2023-07-21 14:58:40 [INFO] Processing 1 temporal features in parallel with 1 workers. Chunksize is 1. If this is above 1, it may take some time for the progress bar to move, as processing is batched. However, this makes for much faster total performance.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████| 1/1 [00:02&lt;00:00,  2.89s/it]
2023-07-21 14:58:43 [INFO] Checking alignment of dataframes - this might take a little while (~2 minutes for 1.000 dataframes with 2.000.000 rows).
2023-07-21 14:58:43 [INFO] Starting concatenation. Will take some time on performant systems, e.g. 30s for 100 features and 2_000_000 prediction times. This is normal.
2023-07-21 14:58:43 [INFO] Concatenation took 0.005 seconds
2023-07-21 14:58:43 [INFO] Merging with original df
</pre></div>
</div>
</div>
</div>
<p>Let’s subset to only see the prediction times that include text again.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_pred_times_with_text</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span>
    <span class="o">~</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;pred_text-st-1_within_730_days_concatenate_fallback_nan&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span>
<span class="p">]</span>
<span class="n">df_pred_times_with_text</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>entity_id</th>
      <th>timestamp</th>
      <th>prediction_time_uuid</th>
      <th>pred_text-st-0_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-st-1_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-st-2_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-st-3_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-st-4_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-st-5_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-st-6_within_730_days_concatenate_fallback_nan</th>
      <th>...</th>
      <th>pred_text-cv-and_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-cv-for_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-cv-in_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-cv-of_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-cv-or_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-cv-patient_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-cv-that_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-cv-the_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-cv-to_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-cv-was_within_730_days_concatenate_fallback_nan</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>244</th>
      <td>7337</td>
      <td>1966-06-28 10:34:00</td>
      <td>7337-1966-06-28-10-34-00</td>
      <td>-0.032579</td>
      <td>0.117177</td>
      <td>-0.049458</td>
      <td>0.009333</td>
      <td>0.013606</td>
      <td>0.021374</td>
      <td>0.001354</td>
      <td>...</td>
      <td>4.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>5.0</td>
      <td>0.0</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>16.0</td>
      <td>4.0</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>755</th>
      <td>8951</td>
      <td>1969-12-22 16:32:00</td>
      <td>8951-1969-12-22-16-32-00</td>
      <td>-0.011282</td>
      <td>0.002961</td>
      <td>0.025957</td>
      <td>-0.015063</td>
      <td>-0.050311</td>
      <td>0.048773</td>
      <td>-0.002749</td>
      <td>...</td>
      <td>1.0</td>
      <td>5.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>8.0</td>
      <td>2.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>896</th>
      <td>2007</td>
      <td>1968-10-15 14:12:00</td>
      <td>2007-1968-10-15-14-12-00</td>
      <td>-0.065502</td>
      <td>0.026975</td>
      <td>-0.042235</td>
      <td>-0.012499</td>
      <td>-0.012820</td>
      <td>-0.003107</td>
      <td>0.025823</td>
      <td>...</td>
      <td>4.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>5.0</td>
      <td>6.0</td>
      <td>2.0</td>
      <td>13.0</td>
      <td>3.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1517</th>
      <td>1728</td>
      <td>1968-05-29 12:27:00</td>
      <td>1728-1968-05-29-12-27-00</td>
      <td>0.003414</td>
      <td>-0.022889</td>
      <td>0.003017</td>
      <td>0.036401</td>
      <td>0.021559</td>
      <td>-0.004627</td>
      <td>0.070992</td>
      <td>...</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>8.0</td>
      <td>11.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>11.0</td>
      <td>5.0</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>1917</th>
      <td>4977</td>
      <td>1968-11-28 16:05:00</td>
      <td>4977-1968-11-28-16-05-00</td>
      <td>0.029870</td>
      <td>0.059029</td>
      <td>0.025774</td>
      <td>0.065304</td>
      <td>0.001232</td>
      <td>0.097216</td>
      <td>0.005217</td>
      <td>...</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>6.0</td>
      <td>7.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>8.0</td>
      <td>4.0</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 397 columns</p>
</div></div></div>
</div>
<p>We can subset further to only include the features we created with the count vectorizer by subsetting to only include columns starting with the feature name (“text-cv”).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_cv_pred_times_with_text</span> <span class="o">=</span> <span class="n">df_pred_times_with_text</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span>
    <span class="p">:,</span> <span class="n">df_pred_times_with_text</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;pred_text-cv&quot;</span><span class="p">)</span>
<span class="p">]</span>
<span class="n">df_cv_pred_times_with_text</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>pred_text-cv-and_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-cv-for_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-cv-in_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-cv-of_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-cv-or_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-cv-patient_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-cv-that_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-cv-the_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-cv-to_within_730_days_concatenate_fallback_nan</th>
      <th>pred_text-cv-was_within_730_days_concatenate_fallback_nan</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>244</th>
      <td>4.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>5.0</td>
      <td>0.0</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>16.0</td>
      <td>4.0</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>755</th>
      <td>1.0</td>
      <td>5.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>8.0</td>
      <td>2.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>896</th>
      <td>4.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>5.0</td>
      <td>6.0</td>
      <td>2.0</td>
      <td>13.0</td>
      <td>3.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1517</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>8.0</td>
      <td>11.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>11.0</td>
      <td>5.0</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>1917</th>
      <td>2.0</td>
      <td>1.0</td>
      <td>6.0</td>
      <td>7.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>8.0</td>
      <td>4.0</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Notice that the text column names are informative wrt. the word they count (e.g. and, for, in, etc.). This is because <code class="docutils literal notranslate"><span class="pre">sklearn_embedding</span></code> uses the <code class="docutils literal notranslate"><span class="pre">.get_feature_names</span></code> method of the sklearn model to set the column names.</p>
</section>
</section>
<section id="writing-your-own-text-embedding-function">
<h2>Writing your own text embedding function<a class="headerlink" href="#writing-your-own-text-embedding-function" title="Permalink to this heading">#</a></h2>
<p>If you want to write your own embedding function, you simply need to write a function that takes a pd.Series of text as the first input and any number of optional keyword arguments. Let’s write a small function to embed long texts using a Huggingface model. Note that this implementation will likely be quite slow. In most cases, the best thing to do would be to embed your data before passing to <code class="docutils literal notranslate"><span class="pre">timeseriesflattener</span></code> and following the procedure outlined in <span class="xref myst">Generating predictors from embedded text</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModel</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">torch</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">huggingface_long_text_embedding</span><span class="p">(</span>
    <span class="n">text_series</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span> <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">chunk_length</span><span class="p">:</span> <span class="nb">int</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Embeds text using a HuggingFace model, splitting the text into chunks of a</span>
<span class="sd">    specified number of characters.</span>

<span class="sd">    Args:</span>
<span class="sd">        text_series: A pandas Series containing the text to be embedded.</span>
<span class="sd">        model_name: The name of the HuggingFace model to use.</span>
<span class="sd">        chunk_length: The number of characters to use in each chunk.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A pandas DataFrame containing the embeddings.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">AutoModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">embeddings</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">text_series</span><span class="p">:</span>
        <span class="n">text_chunks</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">text</span><span class="p">[</span><span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">chunk_length</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">),</span> <span class="n">chunk_length</span><span class="p">)</span>
        <span class="p">]</span>
        <span class="n">tokenized</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
            <span class="n">text_chunks</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span>
        <span class="p">)</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">tokenized</span><span class="p">)</span>
        <span class="c1"># take mean of all tokens in each chunk, then mean of all chunks</span>
        <span class="n">embeddings</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">embeddings</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The function can now be used as an embedding function in a <code class="docutils literal notranslate"><span class="pre">TextPredictorSpec</span></code> and used in the same manner as usual.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">huggingface_long_text_spec</span> <span class="o">=</span> <span class="n">TextPredictorSpec</span><span class="p">(</span>
    <span class="n">timeseries_df</span><span class="o">=</span><span class="n">load_synth_text</span><span class="p">(),</span>
    <span class="n">lookbehind_days</span><span class="o">=</span><span class="mi">730</span><span class="p">,</span>
    <span class="n">fallback</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span>
    <span class="n">aggregation_fn</span><span class="o">=</span><span class="n">concatenate</span><span class="p">,</span>
    <span class="n">feature_base_name</span><span class="o">=</span><span class="s2">&quot;text-hf-long&quot;</span><span class="p">,</span>
    <span class="n">embedding_fn</span><span class="o">=</span><span class="n">huggingface_long_text_embedding</span><span class="p">,</span>
    <span class="n">embedding_fn_kwargs</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;model_name&quot;</span><span class="p">:</span> <span class="s2">&quot;sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2&quot;</span><span class="p">,</span>
        <span class="s2">&quot;chunk_length&quot;</span><span class="p">:</span> <span class="mi">256</span><span class="p">,</span>
    <span class="p">},</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="../faq.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Frequently Asked Questions</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="02_advanced.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Advanced Tutorial</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            <div class="icons">
              <a class="muted-link " href="https://github.com/Aarhus-Psychiatry-Research/timeseriesflattener" aria-label="GitHub">
                <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16">
                    <path fill-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0 0 16 8c0-4.42-3.58-8-8-8z"></path>
                </svg>
            </a>
              
            </div>
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Adding text features</a><ul>
<li><a class="reference internal" href="#the-dataset">The dataset</a></li>
<li><a class="reference internal" href="#generating-predictors-from-embedded-text">Generating predictors from embedded text</a></li>
<li><a class="reference internal" href="#textpredictorspec">TextPredictorSpec</a><ul>
<li><a class="reference internal" href="#featurization-using-sentence-transformers">Featurization using sentence-transformers</a></li>
<li><a class="reference internal" href="#featurization-using-sklearn-models">Featurization using sklearn models</a></li>
</ul>
</li>
<li><a class="reference internal" href="#writing-your-own-text-embedding-function">Writing your own text embedding function</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js?v=b3be93e3"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=4825356b"></script>
    <script src="../_static/scripts/furo.js?v=2c7c1115"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/design-tabs.js?v=36754332"></script>
    </body>
</html>